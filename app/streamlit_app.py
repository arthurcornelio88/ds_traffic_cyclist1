import sys
import os
import streamlit as st
import pandas as pd
import numpy as np
import requests
import json
import time

ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
if ROOT_DIR not in sys.path:
    sys.path.insert(0, ROOT_DIR)

# === Configuration ===
API_URL = st.secrets["api_url"]
ENV = st.secrets["env"]

# === Authentification GCP ===
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['CUDA_VISIBLE_DEVICES'] = "-1"
try:
    gcp_secret = st.secrets["gcp_service_account"]
    with open("/tmp/gcp.json", "w") as f:
        json.dump(dict(gcp_secret), f)
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "/tmp/gcp.json"
    print("‚úÖ GCP credentials configur√©s via Streamlit secrets")
except Exception as e:
    raise RuntimeError("‚ùå Credentials GCP manquants dans st.secrets.")

# === API Request Wrapper ===
def call_prediction_api(url: str, payload: dict, timeout: int = 60):
    try:
        with st.spinner("‚è≥ En attente de la r√©ponse du mod√®le..."):
            response = requests.post(url, json=payload, timeout=timeout)
            response.raise_for_status()
            return response.json()
    except requests.exceptions.Timeout:
        st.error("‚è±Ô∏è L‚ÄôAPI a mis trop de temps √† r√©pondre. Elle est peut-√™tre en cold start.")
    except requests.exceptions.ConnectionError:
        st.error("üîå Impossible de se connecter √† l‚ÄôAPI. V√©rifier l‚ÄôURL ou la disponibilit√© du backend.")
    except requests.exceptions.HTTPError as http_err:
        st.error(f"‚ùå Erreur HTTP {response.status_code} : {response.text}")
    except requests.exceptions.RequestException as req_err:
        st.error(f"‚ö†Ô∏è Erreur inattendue : {type(req_err).__name__} ‚Äî {req_err}")
    return None

# === UI Setup ===
st.sidebar.title("üß≠ Navigation")
page = st.sidebar.selectbox("Choisissez une page :", ["üîç Pr√©diction exemple", "üìÇ Pr√©diction CSV batch"])
st.title("üö≤ Pr√©diction du comptage horaire de v√©los")

model_map = {
    "Random Forest": ("rf", "r2"),
    "R√©seau de Neurones": ("nn", "r2"),
    "RF Classifier (Affluence)": ("rf_class", "f1_score")
}
model_choice = st.radio("Mod√®le √† utiliser :", list(model_map.keys()))
model_type, metric = model_map[model_choice]

# === Exemples ===
raw_samples = [
    {
        'nom_du_compteur': '35 boulevard de M√©nilmontant NO-SE',
        'date_et_heure_de_comptage': '2025-05-17 18:00:00+02:00',
        'coordonn√©es_g√©ographiques': '48.8672, 2.3501',
        'mois_annee_comptage': 'mai 2025'
    },
    {
        'nom_du_compteur': 'Totem 73 boulevard de S√©bastopol S-N',
        'date_et_heure_de_comptage': '2024-11-12 08:00:00+02:00',
        'coordonn√©es_g√©ographiques': '48.8639, 2.3895',
        'mois_annee_comptage': 'novembre 2024'
    },
    {
        'nom_du_compteur': "Quai d'Orsay E-O",
        'date_et_heure_de_comptage': '2024-06-03 15:00:00+02:00',
        'coordonn√©es_g√©ographiques': '48.8784, 2.3574',
        'mois_annee_comptage': 'juin 2024'
    }
]

# === Page Exemple ===
if page == "üîç Pr√©diction exemple":
    idx = st.selectbox("S√©lectionnez une observation :", range(len(raw_samples)), format_func=lambda i: f"Exemple {i+1}")
    selected = raw_samples[idx]
    st.markdown("### üîç Observation s√©lectionn√©e")
    st.json(selected)

    if st.button("üîÆ Lancer la pr√©diction"):
        payload = {
            "records": [selected],
            "model_type": model_type,
            "metric": metric
        }
        st.write("üîß Payload envoy√© :", payload)
        st.write("üîó API URL :", API_URL)
        result = call_prediction_api(API_URL, payload)
        if result:
            pred = result["predictions"][0]
            if model_type == "rf_class":
                st.success("üìä Affluence d√©tect√©e ‚úÖ" if pred == 1 else "üìâ Faible fr√©quentation attendue")
            else:
                st.success(f"üßæ Pr√©diction du comptage horaire : **{round(float(pred))} v√©los**")
    
    with st.expander("ü©∫ Debug API"):
        if st.button("üîÅ Forcer ping API"):
            try:
                ping_response = requests.get(API_URL.replace("/predict", "/docs"), timeout=10)
                if ping_response.status_code == 200:
                    st.success("‚úÖ API en ligne (endpoint /docs accessible).")
                else:
                    st.warning(f"‚ö†Ô∏è API r√©pond mais code inattendu : {ping_response.status_code}")
            except Exception as e:
                st.error(f"‚ùå API inaccessible : {e}")

# === Page CSV ===
elif page == "üìÇ Pr√©diction CSV batch":
    st.header("Pr√©diction sur fichier CSV brut")
    uploaded_file = st.file_uploader("Chargez un fichier brut (.csv)", type="csv")

    if uploaded_file is not None:
        df_csv = pd.read_csv(uploaded_file)
        payload = {
            "records": df_csv.to_dict(orient="records"),
            "model_type": model_type,
            "metric": metric
        }
        result = call_prediction_api(API_URL, payload)
        if result:
            predictions = result["predictions"]
            predictions = np.array(predictions).flatten()
            df_csv["prediction_comptage_horaire"] = predictions.round().astype(int) if model_type != "rf_class" else predictions.astype(int)

            st.markdown("‚úÖ **R√©sultats :**")
            st.dataframe(df_csv.head(20))

            timestamp = time.strftime("%Y%m%d_%H%M%S")
            file_name = f"predictions_{model_type}_{timestamp}.csv"
            csv_output = df_csv.to_csv(index=False).encode("utf-8")
            st.download_button("üì• T√©l√©charger les r√©sultats", csv_output, file_name=file_name, mime="text/csv")
