import streamlit as st
import pandas as pd
from app.mlflow_model_loader import load_pipeline_from_mlflow
import os
import json

# === Initialisation GCP (si secrets pr√©sents) ===
if "gcp_service_account" in st.secrets:
    with open("/tmp/gcp.json", "w") as f:
        json.dump(st.secrets["gcp_service_account"], f)
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "/tmp/gcp.json"

# === Chargement des meilleurs mod√®les via MLflow ===#
@st.cache_resource
def load_best_pipeline(model_type: str):
    return load_pipeline_from_mlflow(model_type, env="dev", test_mode=False)

rf_pipeline = load_best_pipeline("rf")
st.write("‚úÖ Random Forest charg√© :", type(rf_pipeline))

nn_pipeline = load_best_pipeline("nn")
st.write("‚úÖ Neural Net charg√© :", type(nn_pipeline))

# === UI ===
st.sidebar.title("üß≠ Navigation")
page = st.sidebar.selectbox("Choisissez une page :", ["üîç Pr√©diction exemple", "üìÇ Pr√©diction CSV batch"])
st.title("üö≤ Pr√©diction du comptage horaire de v√©los")
modele = st.radio("Mod√®le √† utiliser :", ["Random Forest", "R√©seau de Neurones"])

# === Exemples manuels
raw_samples = [
    {
        'nom_du_compteur': 'Totem 73 boulevard de S√©bastopol S-N',
        'date_et_heure_de_comptage': '2025-05-17 18:00:00+02:00',
        'coordonn√©es_g√©ographiques': '48.8672, 2.3501',
        'mois_annee_comptage': 'mai 2025'
    },
    {
        'nom_du_compteur': '35 boulevard de M√©nilmontant NO-SE',
        'date_et_heure_de_comptage': '2024-11-12 08:00:00+02:00',
        'coordonn√©es_g√©ographiques': '48.8639, 2.3895',
        'mois_annee_comptage': 'novembre 2024'
    },
    {
        'nom_du_compteur': '102 boulevard de Magenta SE-NO',
        'date_et_heure_de_comptage': '2024-06-03 15:00:00+02:00',
        'coordonn√©es_g√©ographiques': '48.8784, 2.3574',
        'mois_annee_comptage': 'juin 2024'
    }
]

# === Page 1 : pr√©diction manuelle
if page == "üîç Pr√©diction exemple":
    idx = st.selectbox("S√©lectionnez une observation brute √† pr√©dire :", range(len(raw_samples)), format_func=lambda i: f"Exemple {i+1}")
    sample_df = pd.DataFrame([raw_samples[idx]])

    try:
        if modele == "Random Forest":
            pred = rf_pipeline.predict_clean(sample_df)[0]
        else:
            pred = nn_pipeline.predict_clean(sample_df)[0][0]

        st.markdown("### üîç Observation s√©lectionn√©e")
        st.json(raw_samples[idx])
        st.success(f"üßæ Pr√©diction du comptage horaire : **{round(pred)} v√©los**")

    except Exception as e:
        st.error("Erreur lors de la pr√©diction :")
        st.code(str(e))

# === Page 2 : pr√©diction sur CSV
elif page == "üìÇ Pr√©diction CSV batch":
    st.header("Pr√©diction sur fichier CSV brut")
    uploaded_file = st.file_uploader("Chargez un fichier brut (.csv)", type="csv")

    if uploaded_file is not None:
        df_csv = pd.read_csv(uploaded_file)
        try:
            if modele == "Random Forest":
                predictions = rf_pipeline.predict(df_csv)
            else:
                predictions = nn_pipeline.predict(df_csv).flatten()

            df_csv['prediction_comptage_horaire'] = predictions.round().astype(int)

            st.markdown("‚úÖ **R√©sultats :**")
            st.dataframe(df_csv.head(20))

            csv_output = df_csv.to_csv(index=False).encode('utf-8')
            st.download_button("üì• T√©l√©charger les r√©sultats", csv_output, file_name="predictions_comptage.csv", mime="text/csv")

        except Exception as e:
            st.error("Erreur lors de la pr√©diction :")
            st.code(str(e))
