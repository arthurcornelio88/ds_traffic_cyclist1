import sys
import os

ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
if ROOT_DIR not in sys.path:
    sys.path.insert(0, ROOT_DIR)

import streamlit as st
import pandas as pd
import os
import json
import time
import numpy as np
import app.app_config as _  # forcer le sys.path side effect
from app.model_registry_summary import get_best_model_from_summary
from PIL import Image
from streamlit_folium import st_folium
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import folium
from folium.plugins import MarkerCluster
from streamlit_folium import folium_static
import plotly.graph_objects as go



def get_secret(key, default=None):
    try:
        return st.secrets[key]
    except Exception:
        return os.getenv(key, default)

env = get_secret("env", "DEV")
gcp_raw = get_secret("gcp_service_account") or get_secret("GCP_SERVICE_ACCOUNT")

if gcp_raw and env == "PROD":
    gcp_dict = json.loads(gcp_raw) if isinstance(gcp_raw, str) else dict(gcp_raw)
    with open("/tmp/gcp.json", "w") as f:
        json.dump(gcp_dict, f)
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "/tmp/gcp.json"
elif env == "DEV":
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "./gcp.json"

# === Fonction de chargement dynamique des mod√®les via summary.json ===
def fetch_best_pipeline(model_type: str):
    print("üì¶ Chargement de get_best_model_from_summary depuis model_registry_summary.py")
    return get_best_model_from_summary(
        model_type=model_type,
        summary_path="gs://df_traffic_cyclist1/models/summary.json",
        metric="r2",
        env="prod",
    )

@st.cache_resource
def load_best_pipeline(model_type: str):
    return fetch_best_pipeline(model_type)

@st.cache_data
def load_clean_data(path="data/comptage-velo-donnees-compteurs.csv"):
    df = pd.read_csv(path, sep=';')
    df.columns = df.columns.str.strip().str.replace(' ', '_').str.lower()
    df['date_et_heure_de_comptage'] = pd.to_datetime(df['date_et_heure_de_comptage'], utc=True).dt.tz_convert('Europe/Paris')
    df['heure'] = df['date_et_heure_de_comptage'].dt.hour
    df['jour_semaine'] = df['date_et_heure_de_comptage'].dt.day_name()
    df["mois"] = df["date_et_heure_de_comptage"].dt.month
    df[['latitude', 'longitude']] = df['coordonn√©es_g√©ographiques'].str.split(',', expand=True).astype(float)
    df = df.dropna(subset=['latitude', 'longitude'])
    return df

# === Exemples manuels
raw_samples = [
    {
        'nom_du_compteur': '35 boulevard de M√©nilmontant NO-SE',
        'date_et_heure_de_comptage': '2025-05-17 18:00:00+02:00',
        'coordonn√©es_g√©ographiques': '48.8672, 2.3501',
        'mois_annee_comptage': 'mai 2025'
    },
    {
        'nom_du_compteur': 'Totem 73 boulevard de S√©bastopol S-N',
        'date_et_heure_de_comptage': '2024-11-12 08:00:00+02:00',
        'coordonn√©es_g√©ographiques': '48.8639, 2.3895',
        'mois_annee_comptage': 'novembre 2024'
    },
    {
        'nom_du_compteur': "Quai d'Orsay E-O",
        'date_et_heure_de_comptage': '2024-06-03 15:00:00+02:00',
        'coordonn√©es_g√©ographiques': '48.8784, 2.3574',
        'mois_annee_comptage': 'juin 2024'
    }
]


# === UI ===
st.sidebar.title("üß≠ Navigation")
menu = ["Pr√©sentation du projet", "Analyse Exploratoire", "D√©marche",
        "Mod√©lisation", "D√©mo"]

selection = st.sidebar.radio(label="", options=menu)

image = Image.open("images/velo.jpg")
resized_image = image.resize((500, 200))
st.image(resized_image, use_container_width=True)

# Titre principal centr√©
st.markdown("""
<h1 style='text-align: center; font-size: 2em; margin-top: -10px;'>
     Pr√©diction du comptage horaire de v√©los
</h1>
<p style='text-align: center; font-size: 1.6em; color: grey; margin-top: -10px;'>
    De Novembre 2024 √† Novembre 2025
</p>
""", unsafe_allow_html=True)


if selection == "Pr√©sentation du projet":
    st.markdown("""
<div style="border:1px solid #ccc; padding:20px; border-radius:10px; text-align:center; font-size:16px">

<p>
Projet r√©alis√© dans le cadre de la formation <strong>Machine Learning Engineer</strong> de 
<a href="https://www.datascientest.com" target="_blank">DataScientest</a><br>
Promotion Alternance Novembre 2025
</p>

<p><strong>Auteurs :</strong><br>
<a href="https://www.linkedin.com/in/arthurcornelio/" target="_blank"><strong>Arthur CORNELIO</strong></a><br>
<a href="https://www.linkedin.com/in/brunohappi17/" target="_blank"><strong>Bruno HAPPI</strong></a><br>
<a href="https://www.linkedin.com/in/ibnemri/" target="_blank"><strong>Ibtihel NEMRI</strong></a>
</p>

<p><strong>Source de donn√©es :</strong><br>
<a href="https://opendata.paris.fr/explore/dataset/comptage-velo-donnees-compteurs" target="_blank">
Comptage v√©los | Open Data | Ville de Paris</a>
</p>

</div>
""", unsafe_allow_html=True)
    st.markdown("""
---

## üéØ Objectifs du projet

Ce projet a pour ambition de :

- **Analyser le trafic cycliste parisien** √† partir de donn√©es r√©colt√©es par des compteurs automatiques.
- Identifier les **zones et cr√©neaux horaires d‚Äôaffluence**.
- Construire des **mod√®les pr√©dictifs** pour anticiper le nombre de cyclistes en fonction du lieu, de la date et de l‚Äôheure.
- Fournir √† la Ville de Paris des **indicateurs utiles** pour optimiser ses politiques d‚Äôam√©nagements cyclables.

---

## üõ†Ô∏è M√©thodologie en bref

- Nettoyage et structuration des donn√©es : standardisation, extraction temporelle, traitement g√©ographique.
- Analyse statistique : identification de pics, moyennes par heure, jour, mois.
- Visualisations : cartes de chaleur, graphiques temporels, pics de trafic.
- Cr√©ation de **mod√®les de r√©gression** (Random Forest, R√©seau de Neurones) pour pr√©dire le **trafic horaire**.
- Construction d‚Äôun **mod√®le de classification binaire** pour d√©tecter les situations d‚Äô**affluence**.
- D√©ploiement dans une **interface interactive Streamlit** accessible et testable.

---

## üìä Exemples de visualisations

Quelques illustrations tir√©es de l‚Äôanalyse exploratoire :

""")

    st.image("images/heatmap_static.png", caption="Carte des zones √† forte affluence cycliste", use_container_width=True)
    st.image("images/traffic_hour_day.png", caption="Trafic moyen par heure selon le jour de la semaine", use_container_width=True)
    st.image("images/pics_barplot.png", caption="Top 20 des pics de fr√©quentation par site de comptage", use_container_width=True)

    st.markdown("""
---

## üíª Application d√©ploy√©e

Les mod√®les les plus performants ont √©t√© int√©gr√©s √† une application Streamlit, permettant de :

- **Tester une pr√©diction** sur un exemple ou un fichier CSV.
- **Comparer plusieurs mod√®les** (Random Forest, R√©seau de Neurones et Random Forest Classifier).
- Obtenir des r√©sultats clairs, exploitables, et exportables.

‚û°Ô∏è Acc√©dez √† l‚Äôonglet **D√©mo** dans la barre lat√©rale pour utiliser l‚Äôinterface.

---
""")

elif selection == "Analyse Exploratoire":
    df_clean = load_clean_data()
    st.header("üîç Analyse Exploratoire")
    st.markdown("""
    Dans cette section, nous explorons les donn√©es de comptage horaire des v√©los collect√©es par la Ville de Paris.  
    L‚Äôobjectif est de comprendre **les grandes tendances de mobilit√© cycliste**, de mettre en lumi√®re **les comportements selon l‚Äôheure, le jour ou le lieu**, et d‚Äôidentifier **les zones √† fort trafic**.

    Les analyses sont bas√©es sur un jeu de donn√©es brut que nous avons **nettoy√©, enrichi et structur√©**, pour le rendre exploitable √† des fins statistiques et de mod√©lisation.
    """)

    st.subheader("üì• Chargement et aper√ßu des donn√©es")
    st.markdown("""
    Le jeu de donn√©es est issu de la plateforme OpenData de la Ville de Paris.  
    Il recense les **comptages horaires de v√©los** effectu√©s par une centaine de capteurs r√©partis dans la ville.  
    Chaque ligne du dataset correspond √† **une heure de mesure pour un compteur donn√©**.

    Il contient les informations suivantes :
    - Date et heure de comptage
    - Nom et position du compteur
    - Nombre de v√©los compt√©s √† chaque heure
    - Coordonn√©es GPS du site de comptage
    """)
    st.write(df_clean.head())

    st.subheader("üßπ Nettoyage des donn√©es")
    st.markdown("""
    Avant toute analyse, plusieurs √©tapes de pr√©traitement ont √©t√© r√©alis√©es :

    - Normalisation des noms de colonnes pour faciliter la manipulation.
    - Conversion des dates au format `datetime` avec fuseau horaire de Paris.
    - Cr√©ation de variables temporelles utiles : **heure, jour, mois, jour de semaine**.
    - S√©paration des **coordonn√©es g√©ographiques** pour les visualisations cartographiques.
    - Suppression des colonnes superflues (liens vers photos, identifiants techniques, etc.).
    - Transformation des colonnes cat√©gorielles pour une meilleure performance m√©moire.
    """)

    st.markdown("### üìä Statistiques globales sur le comptage horaire")
    st.markdown("""
    Les premi√®res statistiques descriptives r√©v√®lent que :

    - Le trafic horaire moyen est de l‚Äôordre de quelques dizaines de v√©los.
    - Les valeurs maximales peuvent d√©passer plusieurs milliers de passages par heure sur certains axes.
    - Une grande dispersion est observ√©e, ce qui justifie une analyse segment√©e par heure et par jour.
    """)
    st.write(df_clean["comptage_horaire"].describe())

    st.markdown("### üìà Moyenne de v√©los par jour de la semaine")
    st.markdown("""
    Ce graphique permet d‚Äôobserver le comportement des cyclistes sur une semaine compl√®te.
    
    - Le trafic est plus √©lev√© en semaine, en particulier du mardi au jeudi.
    - Une baisse notable est visible le samedi et surtout le dimanche.
    - Cela refl√®te clairement l‚Äôusage utilitaire du v√©lo pour les trajets domicile-travail.
    """)
    st.bar_chart(df_clean.groupby("jour_semaine")["comptage_horaire"].mean())

    st.markdown("### üïí Moyenne par heure de la journ√©e")
    st.markdown("""
    On observe deux pics majeurs :

    - Entre 7h30 et 9h le matin.
    - Entre 17h30 et 19h le soir.

    Ces pics correspondent parfaitement aux horaires de travail traditionnels, ce qui confirme l‚Äôusage pendulaire du v√©lo √† Paris.
    """)
    st.line_chart(df_clean.groupby("heure")["comptage_horaire"].mean())

    st.markdown("### üìÜ Moyenne de trafic cycliste par mois")
    st.markdown("""
    Cette analyse montre une saisonnalit√© tr√®s marqu√©e :

    - Les mois les plus actifs sont mai, juin, juillet et septembre.
    - Le creux hivernal (d√©cembre √† f√©vrier) est bien visible.

    Ces variations sont corr√©l√©es √† la m√©t√©o et √† la dur√©e d‚Äôensoleillement, deux facteurs qui influencent fortement la pratique du v√©lo.
    """)
    mois_mean = df_clean.groupby("mois")["comptage_horaire"].mean()
    st.bar_chart(mois_mean)

    st.markdown("### üìä Comparaison du trafic : semaine vs week-end")
    st.markdown("""
    En comparant les courbes :

    - En semaine, les pics sont nets et concentr√©s sur les horaires de bureau.
    - Le week-end, le trafic est plus r√©gulier et r√©parti tout au long de la journ√©e.

    Cela traduit un usage loisir ou touristique le samedi et le dimanche, contre un usage fonctionnel en semaine.
    """)
    df_clean['type_jour'] = df_clean['jour_semaine'].apply(lambda x: 'weekend' if x in ['Saturday', 'Sunday'] else 'semaine')
    trafic_jour_type = df_clean.groupby(['type_jour', 'heure'])['comptage_horaire'].mean().reset_index()
    plt.figure(figsize=(10, 5))
    sns.lineplot(data=trafic_jour_type, x='heure', y='comptage_horaire', hue='type_jour', palette='Set1')
    plt.title("Comparaison du trafic : semaine vs week-end")
    plt.xlabel("Heure")
    plt.ylabel("V√©los/heure")
    st.pyplot(plt.gcf())

    st.markdown("### üìç Top 10 des compteurs les plus fr√©quent√©s")
    st.markdown("""
    Les compteurs les plus actifs sont tous situ√©s sur des axes majeurs :

    - Boulevard de S√©bastopol
    - Boulevard de M√©nilmontant
    - Quai d'Orsay

    Ces zones concentrent une grande partie du trafic cycliste parisien et sont souvent bien am√©nag√©es pour les d√©placements √† v√©lo.
    """)
    top_compteurs = df_clean.groupby("nom_du_compteur")["comptage_horaire"].sum().nlargest(10)
    st.bar_chart(top_compteurs)

    st.markdown("### üîù Top 20 des pics horaires de trafic cycliste")
    st.markdown("""
    Cette analyse isole les moments o√π le trafic a atteint un record horaire pour chaque compteur :

    - Ces pics se produisent quasi exclusivement en semaine.
    - Ils surviennent autour de 8h30 ou 18h, aux heures de pointe.

    Cela confirme la n√©cessit√© de renforcer l‚Äôinfrastructure cyclable sur ces cr√©neaux horaires.
    """)
    df_time_series = df_clean.groupby(['nom_du_compteur', 'date_et_heure_de_comptage'])['comptage_horaire'].mean().unstack(level=0)
    pics_absolus = df_time_series.idxmax()
    analyse_pics = pd.DataFrame({
        'Compteur': pics_absolus.index,
        'Heure_du_pic': pics_absolus.values,
        'Trafic_max': df_time_series.max().values
    }).sort_values('Trafic_max', ascending=False)
    analyse_pics['Heure_du_pic'] = analyse_pics['Heure_du_pic'].dt.strftime('%Y-%m-%d %H:%M')
    fig = px.bar(analyse_pics.head(20), x='Compteur', y='Trafic_max', hover_data=['Heure_du_pic'],
                 color='Trafic_max', title='<b>Top 20 des pics de trafic cycliste</b>',
                 labels={'Trafic_max': 'V√©los/heure', 'Heure_du_pic': 'Moment du pic'},
                 height=500)
    fig.update_layout(xaxis_tickangle=-45)
    st.plotly_chart(fig)

    st.markdown("### üìÖ Trafic moyen par heure selon le jour de la semaine")
    st.markdown("Le trafic varie sensiblement entre semaine et week-end. Les lundis et vendredis ont des profils distincts.")
    df_jour = df_clean.groupby(['jour_semaine', 'heure'])['comptage_horaire'].mean().reset_index()
    ordre_jours = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    plt.figure(figsize=(14, 8))
    sns.lineplot(data=df_jour, x='heure', y='comptage_horaire', hue='jour_semaine',
                 hue_order=ordre_jours, palette='viridis', linewidth=2.5)
    plt.title('Trafic cycliste moyen par heure et jour de semaine', fontsize=16)
    plt.xlabel('Heure de la journ√©e')
    plt.ylabel('Nombre moyen de v√©los/heure')
    plt.grid(alpha=0.3)
    plt.legend(title='Jour', bbox_to_anchor=(1.05, 1))
    st.pyplot(plt.gcf())

    st.markdown("""
    ### üßæ Conclusion de l‚Äôanalyse exploratoire
    - Le trafic cycliste suit un cycle horaire et hebdomadaire r√©gulier, avec des pics matin et soir en semaine.
    - Les week-ends montrent un trafic plus homog√®ne dans la journ√©e.
    - Les zones centrales comme les boulevards ou les quais sont les plus fr√©quent√©es.
    - Les donn√©es sont de qualit√© et pr√™tes pour la mod√©lisation pr√©dictive.
    """)

elif selection == "D√©marche":
    st.header("üß≠ D√©marche")
    st.markdown("""
    Apr√®s avoir explor√© les donn√©es de comptage horaire des v√©los √† Paris, l‚Äôobjectif est d√©sormais de **pr√©voir le trafic cycliste** √† partir de variables temporelles et g√©ographiques.
    
    ### üéØ Objectifs de mod√©lisation

    Deux axes principaux ont guid√© notre d√©marche :

    1. **Pr√©voir le nombre de v√©los par heure** sur un compteur donn√© (mod√®le de r√©gression).
    2. **D√©tecter les situations d‚Äôaffluence** √† partir d‚Äôun seuil propre √† chaque compteur (mod√®le de classification binaire).

    ---

    ### üß© S√©lection des variables explicatives

    Pour estimer le trafic cycliste, nous avons retenu les variables suivantes :

    - **Heure de la journ√©e** : le trafic est tr√®s d√©pendant des horaires (pics de pointe).
    - **Jour de la semaine** : diff√©rence marqu√©e entre semaine et week-end.
    - **Mois de l‚Äôann√©e** : influence saisonni√®re significative.
    - **Coordonn√©es GPS** du compteur : certaines zones sont structurellement plus fr√©quent√©es.

    Ces variables permettent de capter les **effets temporels et spatiaux** du trafic v√©lo.

    ---

    ### üîÑ Pr√©traitement des donn√©es

    Avant l'entra√Ænement des mod√®les, plusieurs transformations ont √©t√© appliqu√©es :

    - Encodage des variables cat√©gorielles (`jour_semaine`, `nom_du_compteur`) via :
      - `OneHotEncoder` pour les mod√®les de r√©gression.
      - `LabelEncoder` pour les mod√®les de classification.
    - S√©paration du jeu de donn√©es en un **jeu d‚Äôentra√Ænement (80‚ÄØ%)** et un **jeu de test (20‚ÄØ%)**.
    - Conversion des coordonn√©es g√©ographiques en `float32` pour optimiser la m√©moire.

    ---

    ### üîç Approche r√©gressive

    Pour pr√©dire le **nombre de v√©los par heure**, nous avons test√© plusieurs mod√®les :

    - **R√©gression lin√©aire** : comme mod√®le de base pour √©valuer les performances minimales attendues.
    - **Random Forest Regressor** : capable de g√©rer les non-lin√©arit√©s et les interactions complexes.
    - **XGBoost Regressor** : algorithme puissant souvent performant sur des donn√©es structur√©es.

    Les pr√©dictions sont √©valu√©es √† l‚Äôaide de **m√©triques classiques** : MAE (erreur absolue moyenne) et R¬≤ (variance expliqu√©e).

    ---

    ### ‚ö†Ô∏è D√©tection d'affluence

    En parall√®le, nous avons formul√© un **probl√®me de classification binaire** :

    - Une ligne est marqu√©e comme une **situation d‚Äôaffluence** (`Affluence = 1`) si le comptage horaire d√©passe la moyenne historique du compteur concern√©.
    - Sinon, elle est marqu√©e comme `Affluence = 0`.

    Cette cible binaire permet d‚Äôentra√Æner un **RandomForestClassifier** capable d‚Äôanticiper les p√©riodes o√π l‚Äôinfrastructure cyclable est susceptible d‚Äô√™tre satur√©e.

    L‚Äô√©valuation du mod√®le se base sur des indicateurs classiques : **accuracy, pr√©cision, rappel, F1-score**, ainsi que **la courbe ROC et l‚ÄôAUC**.

    ---

    ### üîí Fiabilit√© et d√©ploiement

    Pour garantir la reproductibilit√© et une future int√©gration :

    - Les meilleurs mod√®les sont **s√©rialis√©s (via joblib)**.
    - Les **r√©sum√©s de performances sont stock√©s en JSON**, pour suivi ou visualisation ult√©rieure.
    - La pr√©diction ponctuelle est possible √† partir de **valeurs connues** (ex. : heure, jour, compteur‚Ä¶).
    """)

elif selection == "Mod√©lisation":
    st.header("üß† Mod√©lisation")
    st.write("Nous avons utilis√© un RandomForestClassifier pour d√©tecter l‚Äôaffluence...")
    modele = st.radio("Mod√®le √† utiliser :", ["Random Forest", "R√©seau de Neurones", "Random Forest Classifier"])
    if modele == "Random Forest":
        
        # Configuration de la page
        st.title("üö¥‚Äç‚ôÇÔ∏è Mod√©lisation Pr√©dictive du Trafic Cycliste")

        # Section 1: Pr√©sentation des donn√©es
        with st.expander("üìä Donn√©es Utilis√©es", expanded=True):
            st.markdown("""
            **Variables utilis√©es dans le mod√®le :**
            - Variable cible : `comptage_velo` (continu)
            - Features :
                - `nom_du_compteur` (label encod√©)
                - Variables cycliques : `heure_sin`, `heure_cos`, `mois_sin`, `mois_cos`
                - `jour_semaine` (one-hot encoded)
                - `annee` (binaire)
            """)

        # Section 2: R√©sultats de validation crois√©e
        st.header("üìà R√©sultats de Validation Crois√©e")

        cv_scores = [0.91515524, 0.91597844, 0.91690901]
        mean_cv_score = np.mean(cv_scores)

        col1, col2 = st.columns(2)
        with col1:
            st.metric("Moyenne R¬≤ (CV)", f"{mean_cv_score:.4f}", delta_color="off")
        with col2:
            st.metric("√âcart-type (CV)", f"{np.std(cv_scores):.6f}", delta_color="off")

        # Section 3: R√©sultats sur le test set
        st.header("üß™ Performance sur le Test Set")

        # M√©triques du test set
        rmse_rf = 30.13
        r2_rf = 0.9163

        col1, col2 = st.columns(2)
        with col1:
            st.metric("RMSE (Test Set)", f"{rmse_rf:.2f}", delta_color="off")
        with col2:
            st.metric("R¬≤ (Test Set)", f"{r2_rf:.4f}", delta_color="off")

        # Visualisation comparative
        st.subheader("Comparaison Validation Crois√©e / Test Set")
        fig = go.Figure()

        fig.add_trace(go.Bar(
            x=['Validation Crois√©e', 'Test Set'],
            y=[mean_cv_score, r2_rf],
            name='R¬≤ Score',
            text=[f"{mean_cv_score:.4f}", f"{r2_rf:.4f}"],
            textposition='auto',
            marker_color=['#3498db', '#2ecc71']
        ))

        fig.update_layout(
            yaxis_title='Score R¬≤',
            title='Comparaison des Performances',
            showlegend=False
        )
        st.plotly_chart(fig, use_container_width=True)

        # Section 4: Interpr√©tation
        with st.expander("üîç Analyse des R√©sultats", expanded=True):
            st.markdown(f"""
            **Interpr√©tation des performances :**
            
            - üéØ **Score R¬≤ de {r2_rf:.4f} sur le test set** - Le mod√®le explique 91.63% de la variance des donn√©es de test
            - üìè **RMSE de {rmse_rf:.2f}** - L'erreur moyenne est d'environ 30 v√©los/heure
            - üîÑ **Coh√©rence entre CV et test set** - Pas de surapprentissage d√©tect√© (R¬≤ similaire)
            
            **Points forts :**
            - Robustesse confirm√©e sur donn√©es non vues
            - Bonne g√©n√©ralisation gr√¢ce √† la validation crois√©e rigoureuse
            - Faible √©cart entre performance d'entra√Ænement et de test
            
            **Recommandations :**
            - Tester avec plus de donn√©es historiques
            - Ajouter des variables contextuelles (m√©t√©o, √©v√©nements)
            - Optimiser les hyperparam√®tres avec GridSearch
            """)

       


    elif modele == "R√©seau de Neurones":

    # Section 1: Architecture du mod√®le
        with st.expander("üèó Architecture du Mod√®le", expanded=True):
            st.markdown("""
        **Structure innovante combinant :**
        - Couche d'Embedding pour les compteurs v√©lo
        - Features cycliques standardis√©es
        - Architecture profonde avec r√©gularisation
        """)
        
        
            st.code("""
    # Couches principales
    Embedding(input_dim=n_compteurs, 
            output_dim=8)

    Dense(128, activation='relu')
    Dropout(0.3)

    Dense(64, activation='relu')
    Dropout(0.2)

    Dense(32, activation='relu')
    Dense(1)  # Sortie
            """, language='python')
        
        # Section 3: Performance
        st.header("üìä R√©sultats sur le Test Set")

        nn_metrics = {
            "RMSE": 36.24,
            "R¬≤": 0.8789,
            "MAE": 19.12  # Exemple
        }

        col1, col2, col3 = st.columns(3)
        col1.metric("RMSE", f"{nn_metrics['RMSE']:.2f}")
        col2.metric("R¬≤ Score", f"{nn_metrics['R¬≤']:.4f}")
        col3.metric("MAE", f"{nn_metrics['MAE']:.2f}")

        # Section 4: Analyse technique
        with st.expander("üß† Points Cl√©s du Mod√®le", expanded=True):
            st.markdown("""
            **Innovations majeures :**
            - üß© **Embedding des compteurs** : Capture les similarit√©s entre sites de comptage
            - üïí **Features cycliques** : Heure/mois en sin/cos pour pr√©server la cyclicit√©
            - üõ° **R√©gularisation** : Dropout pour √©viter le surapprentissage
            
            **Avantages :**
            - Meilleure capture des motifs complexes
            - Flexibilit√© architecturale
            - Performance proche du Random Forest (R¬≤ = 0.879)
            
            **Am√©liorations possibles :**
            - Ajouter des features m√©t√©o
            - Tester des architectures attention
            - Optimiser les hyperparam√®tres
            """)


    else :
        st.write("Random Forest Classifier est un mod√®le d'ensemble qui combine plusieurs arbres de d√©cision. Il est robuste et peut g√©rer des donn√©es manquantes et non lin√©aires. Il est adapt√© aux donn√©es cat√©gorielles et num√©riques.")
        st.header("üîç Documentation ‚Äì RandomForestClassifier")
        st.markdown("""
    **1. Contexte**  
    Nous utilisons ce mod√®le pour une **classification binaire** : pr√©dire si une p√©riode horaire correspond √† une **affluence** (`1`) ou non (`0`).

    ---

    **2. Mod√®le RandomForestClassifier**  
    Il s‚Äôagit d‚Äôun algorithme d‚Äôensemble combinant plusieurs arbres de d√©cision, chacun entra√Æn√© sur un sous-√©chantillon al√©atoire des donn√©es. La pr√©diction finale est obtenue par vote majoritaire, ce qui am√©liore la robustesse et att√©nue le surapprentissage :contentReference[oaicite:3]{index=3}.

    ---

    **3. Pourquoi ce choix ?**  
    - R√©duit le **surapprentissage** gr√¢ce √† l'agr√©gation des arbres.  
    - Manipule directement les variables num√©riques et cat√©gorielles, sans normalisation pr√©alable :contentReference[oaicite:4]{index=4}.  
    - Robuste au **bruit** et aux **valeurs manquantes**.  
    - Donne des mesures d‚Äô**importance des variables** (impuret√©, permutation) :contentReference[oaicite:5]{index=5}.

    ---

    **4. Hyperparam√®tres utilis√©s**  
    - `n_estimators = 100` : nombre d‚Äôarbres.  
    - `random_state = 42` : assure la reproductibilit√©.

    ---

    **5. √âvaluation sur le jeu test**  
    | M√©trique   | Valeur typique | Interpr√©tation |
    |------------|----------------|----------------|
    | Accuracy   | ~86‚ÄØ%          | Pourcentage global de bonnes pr√©dictions |
    | Precision  | ~82‚ÄØ%          | Parmi les heures pr√©dites comme affluence (`1`), 82‚ÄØ% √©taient correctes.:contentReference[oaicite:6]{index=6} |
    | Recall     | ~82‚ÄØ%          | Parmi les vraies heures d‚Äôaffluence, 82‚ÄØ% ont √©t√© d√©tect√©es. :contentReference[oaicite:7]{index=7} |
    | F1-score   | ~0.82          | Harmonie entre precision et recall, adapt√© aux classes d√©s√©quilibr√©es. :contentReference[oaicite:8]{index=8} |

    **Interpr√©tation**  
    - **Precision** √©lev√©e ‚Üí peu de fausses alertes.  
    - **Recall** √©lev√© ‚Üí peu de pics rat√©s.  
    - **F1-score** √©lev√© (~0,82) ‚Üí bon compromis entre sensibilit√© et fiabilit√©.
    - **Accuracy** est utile, mais insuffisante si la classe "Affluence" est minoritaire :contentReference[oaicite:9]{index=9}.

    ---

    **6. Repr√©sentation visuelle recommand√©e**  
    Pour analyser davantage, on peut afficher :
    - La **matrice de confusion**, pour visualiser les vrais/faux positifs et n√©gatifs.""")
        st.image("images/matrice_de_confusion.png", caption="Matrice de confusion", use_container_width=True)
        st.markdown("""
    - La **courbe ROC-AUC** pour voir le compromis entre taux de vrais positifs et taux de faux positifs.""")
        st.image("images/Courbe_ROC.png", caption="courbe ROC-AUC", use_container_width=True)
        st.markdown("""
    ---

    **Conclusion :**  
    Ce mod√®le offre un bon compromis pour d√©tecter les p√©riodes d'affluence :  
    - **Fiabilit√©** (peu de fausses alertes) gr√¢ce √† la precision √©lev√©e.  
    - **Sensibilit√©** (peu de pics manqu√©s) gr√¢ce au recall √©lev√©.  
    - **√âquilibre** entre les deux gr√¢ce √† un F1-score sup√©rieur √† 0,8, ce qui est id√©al en contexte binaire avec classe minoritaire.
    """)
    # Tu peux √©galement int√©grer ta documentation du mod√®le ici
elif selection == "D√©mo":
    st.header("üö≤ D√©mo de pr√©diction du trafic")
    st.write("Interface de d√©monstration avec exemples manuels ou fichier CSV...")

    # Chargement des pipelines
    rf_pipeline = load_best_pipeline("rf")
    # st.write("‚úÖ Random Forest charg√© :", type(rf_pipeline)) # DEBUG
    st.write("‚úÖ Random Forest charg√© !")

    nn_pipeline = load_best_pipeline("nn")
    # st.write("‚úÖ Neural Net charg√© !", type(nn_pipeline)) # DEBUG
    st.write("‚úÖ Neural Net charg√© !")

    # Fonction utilitaire pour obtenir le bon pipeline
    def get_pipeline(name: str):
        return rf_pipeline if name == "Random Forest" else nn_pipeline

    page = st.sidebar.selectbox("Choisissez une page :", ["üîç Pr√©diction exemple", "üìÇ Pr√©diction CSV batch"])
    modele = st.radio("Mod√®le √† utiliser :", ["Random Forest", "R√©seau de Neurones", "Random Forest Classifier"])

    # === Page 1 : pr√©diction manuelle
    if page == "üîç Pr√©diction exemple":
        idx = st.selectbox("S√©lectionnez une observation brute √† pr√©dire :", range(len(raw_samples)),
                           format_func=lambda i: f"Exemple {i+1}")
        sample_df = pd.DataFrame([raw_samples[idx]])
        pipeline = get_pipeline(modele)

        try:
            pred = pipeline.predict_clean(sample_df)[0]
            if isinstance(pred, (list, np.ndarray)) and isinstance(pred[0], (list, np.ndarray)):
                pred = pred[0]

            st.markdown("### üîç Observation s√©lectionn√©e")
            st.json(raw_samples[idx])
            st.success(f"üßæ Pr√©diction du comptage horaire : **{round(float(pred))} v√©los**")

        except Exception as e:
            st.error("Erreur lors de la pr√©diction :")
            st.code(str(e))
            st.exception(e)

    # === Page 2 : pr√©diction sur CSV
    elif page == "üìÇ Pr√©diction CSV batch":
        st.header("Pr√©diction sur fichier CSV brut")
        uploaded_file = st.file_uploader("Chargez un fichier brut (.csv)", type="csv")

        if uploaded_file is not None:
            df_csv = pd.read_csv(uploaded_file)
            pipeline = get_pipeline(modele)
            try:
                predictions = pipeline.predict(df_csv)
                predictions = predictions.flatten() if hasattr(predictions, "flatten") else predictions
                df_csv['prediction_comptage_horaire'] = predictions.round().astype(int)

                st.markdown("‚úÖ **R√©sultats :**")
                st.dataframe(df_csv.head(20))

                timestamp = time.strftime("%Y%m%d_%H%M%S")
                file_name = f"predictions_{modele.lower().replace(' ', '_')}_{timestamp}.csv"
                csv_output = df_csv.to_csv(index=False).encode('utf-8')
                st.download_button("üì• T√©l√©charger les r√©sultats", csv_output, file_name=file_name, mime="text/csv")

            except Exception as e:
                st.error("Erreur lors de la pr√©diction :")
                st.code(str(e))
                st.exception(e)







