# ğŸ§­ Documentation â€” Architecture MLFlow & Registry pour Bike Traffic

## ğŸ“Œ Vue dâ€™ensemble

Ce projet prÃ©dit le **comptage horaire de vÃ©los Ã  Paris** Ã  partir de donnÃ©es brutes issues des capteurs. Il inclut :

* **3 modÃ¨les ML** : Random Forest (rÃ©gression), Neural Net (rÃ©gression), RF Classifier (classification binaire)
* Un pipeline de traitement + entraÃ®nement + sauvegarde des artefacts
* Un suivi de modÃ¨les via **MLflow** (local/dev ou GCS/prod)
* Une application **Streamlit** connectÃ©e Ã  un registre de modÃ¨les `summary.json` dans GCS

---

## ğŸ—ï¸ 1. Pipelines de traitement

### âœ”ï¸ Nettoyage commun Ã  tous :

* Classe `RawCleanerTransformer`

  * Standardise les noms de colonnes
  * Extrait des features temporelles (`jour`, `heure`, etc.)
  * Parse les coordonnÃ©es gÃ©ographiques
  * Encode les jours de semaine
  * Nettoie `nom_du_compteur`

### âœ”ï¸ ModÃ¨les spÃ©cifiques :

| Pipeline                      | Type                   | Architecture                                                        |
| ----------------------------- | ---------------------- | ------------------------------------------------------------------- |
| `RFPipeline`                  | RÃ©gression             | sklearn `RandomForestRegressor` + preprocessing `ColumnTransformer` |
| `NNPipeline`                  | RÃ©gression             | Keras NN avec embedding + features scalÃ©s                           |
| `AffluenceClassifierPipeline` | Classification binaire | sklearn `RandomForestClassifier` + stratified split                 |

---

## ğŸ§ª 2. EntraÃ®nement (`train.py`)

### ğŸ›ï¸ Mode `dev` vs `prod`

| Mode   | DonnÃ©es                      | MLflow Tracking                               | Artefacts                                                      |
| ------ | ---------------------------- | --------------------------------------------- | -------------------------------------------------------------- |
| `dev`  | CSV local (`./data/`)        | `http://127.0.0.1:5000` local + `mlruns_dev/` | Sauvegarde locale dans `./models/`                             |
| `prod` | DonnÃ©es sur GCS (`gs://...`) | MÃªme MLflow, mais artefacts = GCS             | Export modÃ¨le + rÃ©sumÃ© dans `gs://df_traffic_cyclist1/models/` |

### ğŸ“¦ EntraÃ®nement complet via :

```bash
python src/train.py --env prod
```

* Enregistre chaque run dans MLflow
* Sauvegarde les modÃ¨les dans `tmp_*`
* Upload dans `gs://df_traffic_cyclist1/models/{model_type}/{timestamp}/`
* Met Ã  jour le registre `summary.json`

<img src="img/1.png" alt="Artifacts in prod" width="600" />


### 2.5 ğŸ—„ï¸ MLflow Tracking : `mlruns` en local vs GCP

Le dossier `mlruns/` est la **colonne vertÃ©brale du suivi MLflow**. Il contient :

* les **mÃ©tadonnÃ©es des entraÃ®nements** (hyperparamÃ¨tres, mÃ©triques, tagsâ€¦)
* les **artefacts enregistrÃ©s** (modÃ¨les `.joblib`, `.keras`, images, logsâ€¦)

Le projet distingue deux environnements bien isolÃ©s :

---

#### ğŸ§ª Environnement `dev`

* **Backend Store (local)** :

  * Tous les runs sont sauvegardÃ©s dans le dossier local :

    ```
    ./mlruns_dev/
    â””â”€â”€ <experiment_id>/
        â””â”€â”€ <run_id>/
            â””â”€â”€ meta.yaml, params/, metrics/
    ```

* **Artifact Store (local aussi)** :

  * Les artefacts gÃ©nÃ©rÃ©s (modÃ¨les, logs) sont stockÃ©s dans :

    ```
    ./mlruns_dev/<experiment_id>/<run_id>/artifacts/
    ```

ğŸ’¡ Ce mode permet de travailler en local sans dÃ©pendre du cloud.

---

#### â˜ï¸ Environnement `prod`

* **Backend Store (local)** :

  * Les mÃ©tadonnÃ©es sont toujours stockÃ©es localement :

    ```
    ./mlruns_prod/
    ```

* **Artifact Store (cloud - GCS)** :

  * Les fichiers artefacts sont stockÃ©s dans :

    ```
    gs://df_traffic_cyclist1/mlruns/<experiment_id>/<run_id>/artifacts/
    ```

    <img src="img/2.png" alt="Artifacts in prod" width="600" />

ğŸ¯ Avantage : les modÃ¨les et logs sont accessibles dans le cloud, mais on garde un historique local de tous les entraÃ®nements.

---

### ğŸ” Visualisation dans MLflow

Qu'on soit en `dev` ou `prod`, les expÃ©riences apparaissent dans **la mÃªme interface MLflow UI**, par exemple :

```
http://127.0.0.1:5000/#/experiments/0
```

La diffÃ©rence se fait dans le **chemin dâ€™accÃ¨s aux artefacts** affichÃ© :

* `file:///.../mlruns_dev/...` pour `dev`
* `gs://.../mlruns/...` pour `prod`

---

## ğŸ“š 3. Registre de modÃ¨les (`summary.json`)

### Format :

```json
{
  "timestamp": "2025-06-18T22:59:26.111358",
  "model_type": "nn",
  "env": "prod",
  "test_mode": true,
  "run_id": "abcd...",
  "r2": 0.71,
  "rmse": 54.9,
  "model_uri": "gs://df_traffic_cyclist1/models/nn/20250619_005924/"
}
```

ğŸ§  Câ€™est un historique **append-only** qui stocke tous les modÃ¨les entraÃ®nÃ©s en `prod`.

### âœ¨ GÃ©rÃ© automatiquement par :

```python
update_summary(...)
```

---

## ğŸ” 4. SÃ©lection dynamique des modÃ¨les

L'application Streamlit (et nâ€™importe quel consumer) peut charger le **meilleur modÃ¨le** en fonction :

* du `model_type` (`rf`, `nn`, `rf_class`)
* du `metric` (`r2`, `f1_score`, etc.)
* de lâ€™`env` et du `test_mode`

### Chargement via :

```python
from app.model_registry_summary import get_best_model_from_summary

pipeline = get_best_model_from_summary(
    model_type="nn",
    summary_path="gs://df_traffic_cyclist1/models/summary.json",
    metric="r2",
    env="prod",
    test_mode=True
)
```

ğŸ’¡ Il tÃ©lÃ©charge les artefacts depuis GCS dans `/tmp/`, dÃ©tecte automatiquement les bons sous-dossiers (`rf/`, `nn/`, etc.), et recharge le bon modÃ¨le via `.load()`.

---

## ğŸ›ï¸ 5. Application Streamlit

### âœ… FonctionnalitÃ©s :

* Choix entre `Random Forest`, `Neural Net`, `RF Classifier (Affluence)`
* Mode prÃ©diction manuelle ou batch CSV
* TÃ©lÃ©chargement du fichier de prÃ©diction
* Chargement des modÃ¨les en cache depuis `summary.json`

### ğŸ”’ SÃ©curitÃ© :

* Les credentials GCP sont automatiquement injectÃ©s depuis `st.secrets` ou une variable dâ€™environnement

---

## ğŸ§  Design Patterns clÃ©s

* **`summary.json` comme registre statique et dÃ©centralisÃ©**
* **Logging append-only** â†’ traÃ§abilitÃ© historique
* **Chargement dynamique du â€œbest modelâ€** basÃ© sur des mÃ©triques
* **SÃ©paration claire des modes `dev` et `prod`**
* **Upload vers GCS + MLflow tracking = audit complet**