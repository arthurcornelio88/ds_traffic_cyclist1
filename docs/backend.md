# üìò Documentation ‚Äì Backend `ds_traffic_cyclist1`

## üîß Environnement de d√©veloppement (DEV)

### üìÇ `.env` requis pour chaque service

```env
ENV=DEV
GOOGLE_APPLICATION_CREDENTIALS=gcp.json
```

### ‚ñ∂Ô∏è Lancer les deux API en local

```bash
docker compose up --build
```

Cela instancie deux services :

* `cloudrun-classmodel-backend` (port 8080)
* `cloudrun-regmodel-backend` (port 8000)

---

### üîÅ Endpoints locaux

#### ClassModel API

```bash
curl -X POST 'http://localhost:8080/predict' \
  -H "Content-Type: application/json" \
  -d '{"records": [{"nom_du_compteur": "35 boulevard de M√©nilmontant NO-SE", "date_et_heure_de_comptage": "2025-05-17 18:00:00+02:00", "coordonn√©es_g√©ographiques": "48.8672, 2.3501", "mois_annee_comptage": "mai 2025"}]}'
```

#### RegModel API

```bash
curl -X POST 'http://localhost:8000/predict' \
  -H "Content-Type: application/json" \
  -d '{"records": [{"nom_du_compteur": "35 boulevard de M√©nilmontant NO-SE", "date_et_heure_de_comptage": "2025-05-17 18:00:00+02:00", "coordonn√©es_g√©ographiques": "48.8672, 2.3501", "mois_annee_comptage": "mai 2025"}], "model_type": "nn", "metric": "r2"}'
```

---

## ‚òÅÔ∏è D√©ploiement en production (GCP Cloud Run)

### üß± Configuration initiale

Cr√©er le repository Docker :

```bash
gcloud artifacts repositories create cloud-run-images \
  --project=datascientest-460618 \
  --location=europe-west1 \
  --repository-format=docker \
  --description="Docker repository for Cloud Run images"
```

Cr√©er le secret GCP :

```bash
gcloud secrets create gcp-service-account \
  --data-file=gcp.json
```

Donner acc√®s au service Cloud Run pour lire les secrets :

```bash
gcloud projects add-iam-policy-binding datascientest-460618 \
  --member="serviceAccount:467498471756-compute@developer.gserviceaccount.com" \
  --role="roles/secretmanager.secretAccessor"
```

Configurer Docker pour GCP :

```bash
gcloud auth configure-docker europe-west1-docker.pkg.dev
```

---

## üß© D√©ploiement des services

### üîπ ClassModel API

```bash
cd backend/classmodel

docker build -t europe-west1-docker.pkg.dev/datascientest-460618/cloud-run-images/classmodel-api:latest .

docker push europe-west1-docker.pkg.dev/datascientest-460618/cloud-run-images/classmodel-api:latest

gcloud run deploy classmodel-api \
  --image europe-west1-docker.pkg.dev/datascientest-460618/cloud-run-images/classmodel-api:latest \
  --region europe-west1 \
  --allow-unauthenticated \
  --port 8080 \
  --memory=4Gi \
  --set-env-vars=ENV=PROD \
  --update-secrets=GCP_JSON_CONTENT=gcp-service-account:latest
```

---

### üîπ RegModel API

```bash
cd backend/regmodel

docker build -t europe-west1-docker.pkg.dev/datascientest-460618/cloud-run-images/regmodel-api:latest .

docker push europe-west1-docker.pkg.dev/datascientest-460618/cloud-run-images/regmodel-api:latest

gcloud run deploy regmodel-api \
  --image europe-west1-docker.pkg.dev/datascientest-460618/cloud-run-images/regmodel-api:latest \
  --region europe-west1 \
  --allow-unauthenticated \
  --port 8000 \
  --memory=4Gi \
  --set-env-vars=ENV=PROD \
  --update-secrets=GCP_JSON_CONTENT=gcp-service-account:latest
```

---

## üåê Endpoints en production

### ‚úÖ RegModel API

```bash
curl -X POST "https://regmodel-api-467498471756.europe-west1.run.app/predict" \
  -H "Content-Type: application/json" \
  -d '{"records": [{"nom_du_compteur": "35 boulevard de M√©nilmontant NO-SE", "date_et_heure_de_comptage": "2025-05-17 18:00:00+02:00", "coordonn√©es_g√©ographiques": "48.8672, 2.3501", "mois_annee_comptage": "mai 2025"}], "model_type": "nn", "metric": "r2"}'
```

### ‚úÖ ClassModel API

```bash
curl -X POST "https://classmodel-api-467498471756.europe-west1.run.app/predict" \
  -H "Content-Type: application/json" \
  -d '{"records": [{"nom_du_compteur": "35 boulevard de M√©nilmontant NO-SE", "date_et_heure_de_comptage": "2025-05-17 18:00:00+02:00", "coordonn√©es_g√©ographiques": "48.8672, 2.3501", "mois_annee_comptage": "mai 2025"}]}'
```

---

## üìä Int√©gration Streamlit Cloud

Utiliser les URL suivantes dans le front Streamlit :

* [https://classmodel-api-467498471756.europe-west1.run.app/predict](https://classmodel-api-467498471756.europe-west1.run.app/predict)
* [https://regmodel-api-467498471756.europe-west1.run.app/predict](https://regmodel-api-467498471756.europe-west1.run.app/predict)

---

## üßπ Maintenance

* Nettoyer r√©guli√®rement les artefacts dans : [https://console.cloud.google.com/artifacts](https://console.cloud.google.com/artifacts)
* Le **repository `cloud-run-images`** doit √™tre utilis√© pour tous les d√©ploiements (√©viter `gcf_artifacts` limit√© √† 2GB).

---

## ‚úÖ Conclusion ‚Äì Retours d'exp√©rience (REX)

### üß† Le√ßons apprises

#### 1. **Optimisation de la taille des images et des mod√®les**

* Pour rester dans les quotas du **free tier** (Render, Cloud Run, Cloud Functions), il faut **absolument compresser les mod√®les** et limiter les d√©pendances.
* La taille des containers est cruciale : `Render` limite √† **512MB**, `Cloud Functions` √† **2GB**.
* La meilleure architecture trouv√©e ici est un **d√©ploiement via Cloud Run avec 4Gi de m√©moire**, r√©parti entre **deux backends distincts** :

  * `regmodel-api`
  * `classmodel-api`
* Un seul backend pour tout ? Trop lourd. Deux microservices = d√©ploiements plus efficaces.

#### 2. **Architecture de chargement des mod√®les**

* Initialement, les mod√®les √©taient charg√©s directement depuis **Streamlit Cloud**. R√©sultat : trop lent, trop fragile, ou sinon, crash.
* Ensuite, les mod√®les √©taient **charg√©s √† chaque pr√©diction via API**. Trop co√ªteux, notamment si plusieurs mod√®les doivent √™tre disponibles.
* Solution optimale :

  * **Chargement des "best models" d√®s le d√©marrage du container**
  * Possibilit√© de les **actualiser dynamiquement** via un endpoint `/refresh_model`
  * Les mod√®les sont stock√©s dans un **bucket GCS centralis√©** et lus √† chaque d√©marrage du backend (prod ou dev)

#### 3. **D√©veloppement et DevOps**

* L'aller-retour **dev/prod** est essentiel. Pouvoir reproduire un comportement localement avec `docker compose`, `curl` et `FastAPI` est une immense aide.
* Les temps de build/d√©ploiement sur Cloud Run ou Render sont **tr√®s longs**. Il faut tester **un maximum de logique en local** pour √©viter les frustrations.
* Les requ√™tes `curl` avec des JSON de test sont **indispensables** pour it√©rer vite et valider l'API sans d√©pendre du front.

#### 4. **Gestion des environnements (DEV / PROD)**

* Sur Render, la gestion d'environnements est **compliqu√©e et peu flexible** (versions Python, d√©pendances, secrets...).
* En construisant ses propres images Docker, **tout est sous contr√¥le** :

  * Les bugs apparaissent **en local d‚Äôabord**, donc plus facile √† debugger.
  * L‚Äôenvironnement est **isol√©, reproductible et stable** : ce qui marche en local marchera en prod.
  * On ma√Ætrise la version de Python, les libs, les chemins, les variables ‚Äî **pas de mauvaise surprise au d√©ploiement**.

---